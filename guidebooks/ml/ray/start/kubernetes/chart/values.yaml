clusterName: mycluster
clusterNamespace: default

# Settings for the pod scheduler
mcad:
  enabled: true
  scheduler: default # use the default kubernetes pod scheduler
  # scheduler: coscheduler # https://github.com/kubernetes-sigs/scheduler-plugins/blob/master/pkg/coscheduling/README.md

startupProbe:
  periodSeconds: 10
  failureThrehsold: 10
  initialDelaySeconds: 5

failsafes:
  ray:
    version: 1.13.0
  
# Default values for Ray.

# RayCluster settings:

# image is Ray image to use for the head and workers of this Ray cluster.
# It's recommended to build custom dependencies for your workload into this image,
# taking one of the offical `rayproject/ray` images as base.
image: rayproject/ray:latest
# Define if images should be pulled or taken if present
imagePullPolicy: IfNotPresent
# If a node is idle for this many minutes, it will be removed.
idleTimeoutMinutes: 5
# serviceAccountName is used for the Ray head and each Ray worker.
# It can be set to your particular service account instead of using the default.
# serviceAccountName: ...
# podTypes is the list of pod configurations available for use as Ray nodes.
podTypes:
    # The key for each podType is a user-defined string.
    # Since we set headPodType: rayHeadType, the Ray head pod will use the configuration
    # defined in this entry of podTypes:
    rayHeadType:
        # CPU is the number of CPUs used by this pod type.
        # (Used for both requests and limits. Must be an integer, as Ray does not support fractional CPUs.)
        CPU: 1
        CPUInteger: 1
        # memory is the memory used by this Pod type.
        # (Used for both requests and limits.)
        memory: 1Gi
        # GPU is the number of NVIDIA GPUs used by this pod type.
        # (Optional, requires GPU nodes with appropriate setup. See https://docs.ray.io/en/master/cluster/kubernetes-gpu.html)
        GPU: 0
        # rayResources is an optional string-int mapping signalling additional resources to Ray.
        # "CPU", "GPU", and "memory" are filled automatically based on the above settings, but can be overriden;
        # For example, rayResources: {"CPU": 0} can be used in the head podType to prevent Ray from scheduling tasks on the head.
        # See https://docs.ray.io/en/master/advanced.html#dynamic-remote-parameters for an example of usage of custom resources in a Ray task.
        rayResources: {}
        # Optionally, set a node selector for this podType: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector
        nodeSelector: {}

        # tolerations for Ray pods of this podType (the head's podType in this case)
        #   ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
        #   Note that it is often not necessary to manually specify tolerations for GPU
        #   usage on managed platforms such as AKS, EKS, and GKE.
        #   ref: https://docs.ray.io/en/master/cluster/kubernetes-gpu.html
        tolerations: []
        # - key: "nvidia.com/gpu"
        #   operator: Exists
        #   effect: NoSchedule

    # The key for each podType is a user-defined string.
    rayWorkerType:
        # minWorkers is the minimum number of Ray workers of this pod type to keep running.
        minWorkers: 2
        # maxWorkers is the maximum number of Ray workers of this pod type to which Ray will scale.
        maxWorkers: 3
        # memory is the memory used by this Pod type.
        # (Used for both requests and limits.)
        memory: 1Gi
        # CPU is the number of CPUs used by this pod type.
        # (Used for both requests and limits. Must be an integer, as Ray does not support fractional CPUs.)
        CPU: 1
        CPUInteger: 1
        # GPU is the number of NVIDIA GPUs used by this pod type.
        # (Optional, requires GPU nodes with appropriate setup. See https://docs.ray.io/en/master/cluster/kubernetes-gpu.html)
        GPU: 0
        # rayResources is an optional string-int mapping signalling additional resources to Ray.
        # "CPU", "GPU", and "memory" are filled automatically based on the above settings, but can be overriden;
        # For example, rayResources: {"CPU": 0} can be used in the head podType to prevent Ray from scheduling tasks on the head.
        # See https://docs.ray.io/en/master/advanced.html#dynamic-remote-parameters for an example of usage of custom resources in a Ray task.
        rayResources: {}
        # Optionally, set a node selector for this Pod type. See https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector
        nodeSelector: {}

        # tolerations for Ray pods of this podType
        #   ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
        #   Note that it is often not necessary to manually specify tolerations for GPU
        #   usage on managed platforms such as AKS, EKS, and GKE.
        #   ref: https://docs.ray.io/en/master/cluster/kubernetes-gpu.html
        tolerations: []
        # - key: nvidia.com/gpu
        #   operator: Exists
        #   effect: NoSchedule

    # Optionally, define more worker podTypes
    # rayWorkerType2:
    #   minWorkers: 0
    #   maxWorkers: 10
    #   memory: ...
