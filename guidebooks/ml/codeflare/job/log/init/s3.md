---
imports:
    - ml/ray/run/logs-in-s3.md
---

S3 filepath (i.e. bucket/folder/...) for the logs.
```shell
export S3_LOGDIR="${S3_BUCKETRAYLOGS}/codeflare/${JOB_ID}"
```

Local staging directory for the logs.
```shell
export LOGDIR_STAGE=$(mktemp -d -t logdir-stage)
```

Store the job id in the stage.
```shell
echo ${JOB_ID} > ${LOGDIR_STAGE}/jobid.txt
```

An `s3://` formatted version of the S3 filepath.
```shell
export LOGDIR_URI="s3://${S3_LOGDIR}"
```

A minio-client formatted version of the S3 filepath.
```shell
export LOGDIR_MC="s3/${S3_LOGDIR}"
```

Staging location for logs, from any guidebooks.
```shell
export STREAMCONSUMER_LOGS="${LOGDIR_STAGE}/logs/"
```
```shell
mkdir -p "${LOGDIR_STAGE}/logs"
```

Staging location for events, from any guidebooks.
```shell
export STREAMCONSUMER_EVENTS="${LOGDIR_STAGE}/events/"
```
```shell
mkdir -p "${LOGDIR_STAGE}/events"
```

Staging location for resource utilization information, from any guidebooks.
```shell
export STREAMCONSUMER_RESOURCES="${LOGDIR_STAGE}/resources/"
```
```shell
mkdir -p "${LOGDIR_STAGE}/resources"
```

Periodically copy the staging directory up to the final S3
location. Note: I can't find a way to completely silence `mc cp`, and
it emits progress to stdout, hence the `> /dev/null`

```shell.async
while true; do
  sleep ${S3_SYNC_INTERVAL-10}
  (cd ${LOGDIR_STAGE} && mc --config-dir ${MC_CONFIG_DIR} cp --recursive --quiet --preserve . ${LOGDIR_MC} > /dev/null)
done
```
