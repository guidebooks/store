---
imports:
    - ./choose-data
    - ./_roberta
---

# Pre-Train a RoBERTa Language Model from Pre-tokenized Data

The [CodeFlare](https://codeflare.dev/) [model architecture](https://developer.ibm.com/articles/cc-machine-learning-deep-learning-architectures/) uses [RoBERTa](https://huggingface.co/docs/transformers/model_doc/roberta), which
is a robustly optimized method for pretraining natural language
processing (NLP) systems.
